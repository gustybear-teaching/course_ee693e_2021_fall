---
title: "01: FedHome: Cloud-Edge based Personalized Federated Learning for In-Home Health Monitoring Qiong Wu, Xu Chen, Zhi Zhou, Junshan Zhang"
date: 2021-11-15
type: book
commentable: true

# Provide the name of the presenter
summary: "Presenter(s): Clyde James Felix, Saige Dacuycuy, Nguyen Banh"

# Provide other tags that describe the paper
tags:
- teaching
- ee693e
- Federated Learning

---

***
## Paper Summary
Data shows that the population of elders will increase significantly. This will lead to more elders needing medical care in thier personal homes. Today, more IoT technologies and software solutions are being used in the telehealth applications, such as this one! For this application, a home health monitoring system is useful for the elders who are in need of medical assisstance. An emerging technology of Artificial Intelligence can be utilize to solve these problems. For an AI system, each home will have to send data into a machine learning model in a cloud server. The server will then be used for user services. This approaches poses security risks by sending data wirelessly. This paer proposes in using Federated Learning to send model parameters, instead of data, wirelessly to the cloud server. This paper also explains the approach to solve Federated Learning problems using Generative AutoEncode and other algorithms. The paper shows good performance results using the AI system.
***

## Presentation
{{< youtube F2g9b7Yhn18 >}}

***

## Review
### Strengths
- Ensures data privacy by sending model parameters (using homomorphic encryption) and not actual data.
- Ensures higher accuracy by adding personalization schemes per edge clients.

### Weaknesses
- This system is computationally heavy.
- Hyper parameters might be harder to tune, and there are alot of them

### Detailed Comments
The world's population aged 60 and above is projected to grow to 1.2 billion in 2025 and 2 billion by 2050. Due to the combined sensing, processing, and communication capabilities of IoT devices, the Internet of Things (IoT) is set to make significant advancements in healthcare systems. Given that users' health data entails individual privacy, gathering and keeping an abundance of health monitoring data would entail a significant danger of privacy leakage. Federated learning (FL), which Google suggested in 2016, may alleviate the privacy issue in community healthcare by respecting data ownership and preserving data locality for application deployment at scale. FedHome is a cloud-based federated learning platform for individualized health monitoring in the home.

As the model trained on both the cloud and the edges, they present a unique generative convolutional autoencoder (GCAE) network. It avoids downloading sensitive data from users to a centralized cloud server, hence lowering network latency and alleviating privacy concerns. FedHome is a cloud-based, customized, federated learning platform for remote health monitoring in the home. FedHome develops a worldwide shared model from distributed houses with the assistance of a central server. It achieves a high accuracy of 95.41 percent, outperforming the commonly used convolutional neural network (CNN) method by more than 7.49 percent.

FedHome is a cloud-based health monitoring system for the house that consists of a cloud server and a network of edge computing nodes. Users may train a machine learning model called MFED without uploading or revealing their data to a central cloud server. Its mission is to develop artificial intelligence algorithms for healthcare applications ranging from hospital to home. Architecture with a Cloud-Edge. By using federated learning, all users may combine their local models into a global model in the cloud to facilitate knowledge transfer without revealing their private data to the outside world.

Additionally, family members may exchange data and train a shared model at the edge. The cloud model is built on generic data sets from distant houses, which may not accurately reflect the unique features of each target user. GCAE is well-suited for federated learning since it is lightweight and can significantly minimize communication costs between the cloud and the edges.

FedHome uses deep neural networks to train both the cloud model and the client model at the edges (DNNs). The learning issue is essentially a problem of empirical risk reduction. The FedHealth framework makes use of homomorphic encryption to prevent model parameter information leaks during the learning phase for in-home health monitoring. As part of a bigger effort by WeBank's AI branch, the data privacy concept has been examined and used in FL contexts.

They suggest that a generative prediction model be learned in both the cloud and at the edges. For both the encoder and decoder, we adopt a convolutional neural network (CNN) as the primary architecture. Without submitting to the cloud, the model is always maintained by the local user. FedHome's training process begins with the cloud server managed by a smart healthcare service provider initializing the GCAE model and then sending it to all participating IoT devices (e.g., smartphones). Each user of an IoT device can then offload the training task to the trustworthy edge for fast computation. Overlay sampling is a frequently used technique of oversampling to obtain a class-balanced dataset.

GCAE not only generates new data but also significantly minimizes transmission overhead. Both the encoder and decoder employ convolutional neural networks (CNNs) with shared parameters. GCAE enables significant reductions in communication overhead without sacrificing performance. It is critical in federated environments like mobile banking and e-commerce. Each home user may further develop a tailored model by combining the data with a class-balanced dataset.

FedHome is therefore adaptable to a wide variety of privacy-preserving healthcare applications. Additionally, it may use additional deep neural networks that are optimized for a particular job, such as an attention network for dementia prediction.


### Implementation

The FedHome Framework follows three algorithms (Fig. 1). We start off with the first algorithm, which is the learning procedure of FedHome. The edge trains a globally shared GCAE model for in-home health monitoring under the coordination of a cloud server by leveraging federated learning.

The second algorithm is the generation of a local model using the initial global model and the user's data. The local model parameters is being sent to the cloud. This process repeats until the GCAE model on the cloud converges.

Afterwards, the trained GCAE model can be deployed in the edge server of each home. The third algorithm is the personalization step. Each home user can further learn a personalized model by synthesizing a class-balanced dataset with their personal data and then refining model parameters with the generated dataset. In this case, everyone will have a unique learning plan after training the generalized dataset.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2021_fall/blob/4ab40142ebaa0e39396710bd12b5a6584c568461/week_12/images/Wu_Fig1.png" title="Fig. 1: FedHome Framework." width="160" >}}

The GCAE is meant to be a predictive model in both the cloud and edges. The architecture of the GCAE is shown in Fig. 2. The health information is sent through an encoder that focuses on learning the feautures. There is also a decoder that calculates the reconstruction loss between the original data and the reconstructed data. The Multi-Lyaer Perceptron (MLP) predicts the likelihood of the class label. In this case, it's obective is to minimize the difference score between the actual label and predicted probability distributions for all classes. From this difference, as well as the difference from the original data vs. the reconstructed data, the total loss of information in a system can be observed.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2021_fall/blob/4ab40142ebaa0e39396710bd12b5a6584c568461/week_12/images/Wu_Fig2.png" title="Fig. 2: Architecture of the generative convolution autoencoder." width="320" >}}


### Experimentation

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2021_fall/blob/4ab40142ebaa0e39396710bd12b5a6584c568461/week_12/images/Wu_Table1.png" title="Table 1: Human activity in MobiAct dataset." width="320" >}}

The study is based on a publicly accessible human activity recognition dataset called MobiAct. There are 57 volunteers wearing a Samsung Galaxy S3 smartphone equipped with an accelerometer and gyroscope sensor. The accelerometer and angular velocity signals are recorded while performing predefined activities. This dataset is meaningful because it can provide relevant application scenario to mimic in-home health monitoring through human activity recognition.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2021_fall/blob/4ab40142ebaa0e39396710bd12b5a6584c568461/week_12/images/Wu_Fig4.png" title="Fig. 3 Data preprocessing procedure." width="320" >}}

This figure shows how the human activity model is translated on the Cartesian coordinate system. The variables described in the system is the acceleration and the angular velocity of the human body based on the certain activities. The tri-axial acceleration and angular velocity are plotted for one activity and mapped into pixels as an RGB image. This can be useful as the input for the GCAE architecture.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2021_fall/blob/4ab40142ebaa0e39396710bd12b5a6584c568461/week_12/images/Wu_Fig5.png" title="Fig. 4 Test accuracy and time cost under different number of participating clients in each communication round." width="320" >}}

In federated learning settings, there are three key parameters that influence the performance of federated learning. One of them being K, the number of participating clients in each communication round. An experiment is conducted to see the effect of K on the test accruacy in each communication round.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2021_fall/blob/4ab40142ebaa0e39396710bd12b5a6584c568461/week_12/images/Wu_Fig6.png" title="Fig. 5 Test Accuracy vs communication rounds under different combinations of B and E." width="320" >}}

The other two parameters that influence the performance of federated learning, are E, training passes over each client's local data and B, local minibatch size. By fixing K, combinations of B and E can show varying accuracy of human activity recognition.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2021_fall/blob/4ab40142ebaa0e39396710bd12b5a6584c568461/week_12/images/Wu_Table2.png" title="Table 2: Test accuracy of the models in human activity recognition." width="320" >}}

This table illustrates the performances of different human activity recognition approaches under both balanced and imblanced data cases. For each method, the average and standard deviation of test accuracy is computed and the training and prediction processes are repeated a total of 5 times.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2021_fall/blob/4ab40142ebaa0e39396710bd12b5a6584c568461/week_12/images/Wu_Table3.png" title="Table 3: The average precision, recall and f1-score for each activity." width="320" >}}

This table illustrates the performance on all the metric for all activities. FedHome measures the average precision, recall and fI-score over all 30 users for each activity.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2021_fall/blob/4ab40142ebaa0e39396710bd12b5a6584c568461/week_12/images/Wu_Fig7png" title="Fig. 6 Test accuracy of different FL approaches under home data partition." width="320" >}}

This figure shows the comparison of federated learning approaches and its test accuracy of 30 users. 

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2021_fall/blob/4ab40142ebaa0e39396710bd12b5a6584c568461/week_12/images/Wu_Fig8png" title="Fig. 7 Performance of FedHome framework when facing new users." width="320" >}}

The authors investigate the generalization ability of FedHome when facing new users. Five new users are selected and then the learned cloud model is distributed to the five users. After training using the user's personal data, the local model is obtained.


### Audience Questions
1.	What are the advantages of Generative Convolutional Autoencoder (GCAE) compared to other standard Auto Encoders (AE)?

    By using the generative component, GCAE can extract more features than other regular AutoEncoders. GCAE also consists only a small number of model parameters, which can significantly reduce communication overhead during model transfer.

2.	During the personalization step, is it done over the same parameters for all the subjects or is it done using different parameters for different subjects?

    Personalization algorithms can require different parameters to improve performance for each subjects. Each subject obtains a generalized learning plan from multiple users of the same health situation, but eventually different parameters unique to the user can develop a personalized learning plan.

3.	Does CNN require large resources for computation?

    CNN is usually computationally heavy. This depends on the size of the data, along with other CNN parameters such as filter size, strides, padding, and others.
