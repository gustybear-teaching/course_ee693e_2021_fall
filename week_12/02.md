---
title: "02: 2FA-PP: 2nd Factor Phishing Prevention
Enis Ulqinaku, Daniele Lain, Srdjan Capkun"
date: 2021-09-02
type: book
commentable: true
# Provide the name of the presenter
summary: "Presenter(s): Alvin Yang and Thomas Yang"
# Provide other tags that describe the paper
tags:
- teaching
- ee693e
- fraud
- 2FA
---
***
## Paper Summary
Two factor authentication (2FA) schemes help provide a strong user authentication alongside the traditional password. However, many 2FA schemes are still vulnerable to phishing attacks, where the 2FA can be phished along with the password. This is where the paper proposes 2nd Factor Phishing Prevention, 2F-PP, which uses the browserâ€™s API to communicate with an external device, such as a mobile phone, and lets the phone check what domain the browser is connected to. With this domain check, the phone can decide whether to authenticate the log-in or reject it and alert the user of an attempted attack.
***
## Presentation
{{< youtube PH9HPmnIK24 >}}
***
## Review
### Strengths
- 2FA-PP requires little user interaction to set up, and no user interaction per login once set up.
- Time added by 2FA-PP is negligible, adding about less than a seconds worth towards the login time.
- Utilizes currently available software and hardware used in current 2FA schemes, such as bluetooth and browser APIs, so implementation into current systems is feasible.

### Weaknesses
- As 2FA-PP is timing based, attackers within the same locality as the user (such as on the same Hotspot or Wi-Fi) has a significantly higher chance at success than other attackers
### Detailed Comments


### Methods
There were four methods of MR imaging which were experimented upon. The first method they wanted to test was CS reconstruction performance and reconstruction artifacts with increased undersampling. This was done via simulation to examine the performance of CS reconstruction with increased undersampling compared to low resolution (LR) and zero-filling with density compensation (ZF-w/dc) and also to demonstrate the advantage of variable density random undersampling over uniform density. The simulation consisted of a constructed phantom image with 18 features in six different sizes and three different intensities which were randomly distributed to simulate an angiogram.

The second method the authors wanted to test was undersampling 2D cartesian sampling in the presence of noise. A 2D Cartesian spin-echo sequence was used to scan the phantom image in order to test the already accepted knowledge that CS reconstruction holds stable with the presence of noise and can also perform nonlinear edge preserving denoising of the image.

The third method tested was multislice 2DFT fast spin-echo brain imaging. Since brain images exhibit transform sparsity in the wavelet domain with most scans being multislice acquisitions, it is thought that CS has potential to reduce acquisition time or improve resolution within brain images. A T2 weighted multislice k-space data set was filled with a healthy brain using fast spin-echo sequence. Different sets of 80 phase-encodes were chosen randomly per slice with variable density and an acceleration factor of 2.4. Then a CS wavelet transformation was done to create sparsity along with a TV penalty. Computation time and memory load were decreased by doing 2D reconstructions of the 3D problem in the x-y and y-z planes.

The last method tested was contrast-enhanced 3D angiography. Angiograms are sparse and need to cover a very large field of view with relatively high resolution and crucial scan time which make them good candidates for CS reconstruction. The blood vessels are bright with very low background signal and are easily sparsified by both wavelet and finite differences transforms. A controlled test with simulated k-space for various degrees of undersampling was done before actually testing the method with a true k-space data set done on a first-pass abdominal contrast enhanced angiogram.

### Experimentation
The simulation results of the CS reconstruction performance and reconstruction artifacts with increased sampling in Figure 1 below found that the CS at 8 fold acceleration and variable density random undersampling had the best results. The LR reconstruction case showed a decrease in resolution with acceleration and the zero-filling showed a decrease in SNR due to incoherent interference. The higher accelerations in CS reconstruction led to increased feature losses.

The reconstruction results from the 2DFT CS reconstruction in the presence of noise (Figure 2) showed that the case of denoising with nonlinear edge-preserving TV denoising seen in part d of the figure was the best scenario for reconstruction. Compared to the SNR of 6.17 in the fully sampled phantom scan with no undersampling in part a, the ZF-w/dc reconstruction in part b had significant apparent noise, mostly due to incoherent aliasing artifacts from undersampling as well as a noise increase from the density compensation which yielded a decreased SNR of 3.79. The artifacts were suppressed by CS reconstruction in figure c which recovered the noisy image for an SNR of 9.84. However, by increasing the RMS consistency parameter to 0.1 in the nonlinear edge-preserving case, the results showed a dramatic increase in SNR to 26.9 without damaging the image quality.

The results from the multislice fast spin-echo brain imaging test  (Figure 3) had shown that the CS reconstruction exhibited significant resolution improvement over the Nyquist sampling, ZF-w/dc, and LR reconstructions. This can be seen in part a where a comparison is done with coronal and axial slices. In part b, they further tested CS reconstructions with several undersampling schemes which correspond to those in part c. It was found that reconstruction with constant data undersampling for all slices had low resolution aliasing artifacts with more pronounced artifacts in uniform undersampling. However, when each slice was undersampled differently, the artifacts significantly reduced because the theoretical TPSF peak interference is significantly smaller, enabling better recovery of the components. Therefore, variable density undersampling outperforms uniform undersampling significantly.

Lastly, the contrast enhanced 3D angiography results are shown in Figure 4 for a region of interest in the maximum intensity projection of the reconstruction results as well as a slice reconstruction from 10-fold acceleration. The left column depicts LR reconstruction exhibiting a decrease in resolution with acceleration characterized by loss of small structures and diffused blood vessel boundaries. The middle column depicts ZF-w/dc reconstruction exhibiting a decrease in SNR from incoherent interference obscuring small and dim vessels. The right column uses CS reconstruction which is exhibiting good reconstruction of vessels even at very high accelerations. The resolution and contrast are preserved with almost no loss of info up to 10-fold acceleration and not much less at 20 fold.
In Figure 5, the reconstruction results from the first pass contrast experiment in which the imaged patient has an aortobifemoral bypass graft. The arrows indicate high-grade stenosis in the native right common iliac artery. Part a shows the image with reconstruction from a complete data set. At 5 fold acceleration, we see diffused boundaries in LR (part b), a decrease in SNR for zero-fill (part c), and good vessel reconstruction for CS (part d). Flow across the stenosis is visible in CS but not for LR and ZF.


### Discussion


### Questions
(1) Any ideas on how to improve MRI reconstruction besides standard CS?


(2) What are some major disadvantages that you see in this experiment?

The paper mentions that from variable density undersampling, only the weak intensity objects have reconstruction errors. So this means that lower energy higher-frequency components are ignored. This could be a problem since maybe important detail can be in the high frequency regions. They should probably account for better optimization that accounts for high and low frequency k-space data separately.

(3) Given that this article was published in 2007, do you aware of any real-world applications using this study?
